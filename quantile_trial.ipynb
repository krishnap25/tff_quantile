{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "tff.backends.test.set_test_execution_context()  # for secure aggregation\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "print(f'TF version: {tf.__version__}\\nTFF version: {tff.__version__}')\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TF version: 2.7.0-dev20210829\n",
      "TFF version: 0.19.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from hierarchical_histogram.hierarchical_histogram import build_hierarchical_histogram_computation\n",
    "from hierarchical_histogram.hierarchical_histogram_decoder import HierarchicalHistogramDecoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Goal\n",
    "Construct a hierarchical histogram from synthetic data and compute its median (0.5-quantile). \n",
    "\n",
    "For simplicity, I will start with 'no-noise' DP and add noise later once I get the semantics of these methods right. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "lower_bound = 0\n",
    "upper_bound = 1\n",
    "num_bins = 10\n",
    "hihi_computation = build_hierarchical_histogram_computation(\n",
    "    lower_bound=lower_bound, upper_bound=upper_bound, num_bins=num_bins,\n",
    "    dp_mechanism='no-noise',\n",
    "    # dp_mechanism='distributed-discrete-gaussian', noise_multiplier=0.1, \n",
    "    expected_clients_per_round=100)\n",
    "\n",
    "client_losses = np.linspace(0, 1, 100)[:, None].astype(np.float32).tolist()\n",
    "# `client_losses` is a list of 100 entries, each of which is a single-element list\n",
    "print('client losses sample:', client_losses[:4])  \n",
    "\n",
    "# Create a tf Dataset for each client. Each client has only one single scalar. \n",
    "# `hihi_computation` expects a `tf.data.Dataset` at each client.\n",
    "client_losses_ds = [tf.data.Dataset.from_tensor_slices(l) for l in client_losses]\n",
    "\n",
    "hist = hihi_computation(client_losses_ds)  # compute the histogram from the data\n",
    "decoder = HierarchicalHistogramDecoder(hist)  # build the decoder object\n",
    "decoder.enforce_consistency()  # required before running quantile query\n",
    "\n",
    "bin_id = decoder.quantile_query(0.481)  # quantile query returns the index of leaf\n",
    "layer_of_leaf = decoder._num_layers - 1  # layer id of the leaf\n",
    "# Compute the value of the node. Does this give us the quantile estimate?\n",
    "# quantile_estimate = decoder.node_query(layer_of_leaf, bin_id) \n",
    "def transform_from_unit_interval(x):\n",
    "    return lower_bound + x  * (upper_bound - lower_bound)\n",
    "quantile_estimate = 0.5 * (\n",
    "    transform_from_unit_interval(bin_id / num_bins)  +\n",
    "    transform_from_unit_interval(min(1, (bin_id+1) / num_bins))\n",
    ")\n",
    "\n",
    "print(f'bin_id: {bin_id}\\tlayer_id: {layer_of_leaf}\\nQuantile estimate: {quantile_estimate}')\n",
    "print(f'Type of histogram: {hist.dtype}\\tType of quantile estimate: {type(quantile_estimate)}')\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "client losses sample: [[0.0], [0.010101010091602802], [0.020202020183205605], [0.03030303120613098]]\n",
      "bin_id: 9\tlayer_id: 4\n",
      "Quantile estimate: 0.95\n",
      "Type of histogram: <dtype: 'int32'>\tType of quantile estimate: <class 'float'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Questions:\n",
    "1. Why is `hist.dtype` int32? I expect it to be float32, same as the data. \n",
    "2. As per the type signatures, `decoder.node_query`'s return type is float. Why does it return an integer?\n",
    "3. My data is uniformly spaced between 0 and 1. Therefore, the 0.5-quantile should be ~0.5. In this sense, a `bin_id` of 4 is reasonable to me. How do I obtain the actual float32 value of the quantile from this?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pyt19': conda)"
  },
  "interpreter": {
   "hash": "7d027ed89e20f0c81a7f0a48527f117f0b2b112da57a9a9c0d3883ca1b4ca1de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}